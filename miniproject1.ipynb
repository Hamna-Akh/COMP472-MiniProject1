{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from random import randint\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from matplotlib.backends.backend_pdf import PdfPages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dataset Preparation & Analysis\n",
    "\n",
    "## 1.2 - Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### goemotions.json.gz must be placed in the parent of current directory\n",
    "\n",
    "path = os.getcwd()\n",
    "f = gzip.open(os.path.abspath(os.path.join(path, os.pardir)) + '/goemotions.json.gz', 'rb')\n",
    "file_content = f.read()\n",
    "data_list = json.loads(file_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3.1 - Extracting the posts and 2 sets of labels (emotion and sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = []\n",
    "emotions = []\n",
    "sentiments = []\n",
    "\n",
    "for entry in data_list:\n",
    "    posts.append(entry[0])\n",
    "    emotions.append(entry[1])\n",
    "    sentiments.append(entry[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3.2 - Plotting the distribution of the posts in each category and saving the graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_freq = []\n",
    "emotion_labels = []\n",
    "sentiment_freq = []\n",
    "sentiment_labels = []\n",
    "\n",
    "# Get n different colors\n",
    "def getColors(n):\n",
    "    colors = []\n",
    "    for i in range(n):\n",
    "        color = '#%06X' % randint(0, 0xFFFFFF)\n",
    "        while color in colors:\n",
    "            color = '#%06X' % randint(0, 0xFFFFFF)\n",
    "        colors.append(color)\n",
    "    return colors\n",
    "\n",
    "# Breakdown emotions list into frequencies and labels\n",
    "for emotion in emotions:\n",
    "    if emotion in emotion_labels:\n",
    "        index = emotion_labels.index(emotion)\n",
    "        emotion_freq[index] = emotion_freq[index] + 1\n",
    "    else:\n",
    "        emotion_labels.append(emotion)\n",
    "        emotion_freq.append(1)\n",
    "\n",
    "# Breakdown sentiments list into frequencies and labels\n",
    "for sentiment in sentiments:\n",
    "    if sentiment in sentiment_labels:\n",
    "        index = sentiment_labels.index(sentiment)\n",
    "        sentiment_freq[index] = sentiment_freq[index] + 1\n",
    "    else:\n",
    "        sentiment_labels.append(sentiment)\n",
    "        sentiment_freq.append(1)\n",
    "\n",
    "with PdfPages('frequency_charts.pdf') as pdf:\n",
    "    # Plotting emotions frequencies\n",
    "    plt.pie(emotion_freq, labels=emotion_labels, \n",
    "            startangle=90, colors=getColors(len(emotion_labels)),\n",
    "            rotatelabels=True, counterclock=False, \n",
    "            explode=[0.1 for emotion in emotion_labels], shadow=True)\n",
    "    plt.title('Emotion Frequencies', y=1.25)\n",
    "    # Because many labels and small frequencies, \n",
    "    # manually calculating percentages for display in legend instead of chart\n",
    "    emotion_distribution = [(count/sum(emotion_freq))*100 for count in emotion_freq]\n",
    "    plt.legend(title='Emotions:', labels=[f'{l}: {s:0.1f}%' for l, s in zip(emotion_labels, emotion_distribution)],\n",
    "            bbox_to_anchor=(1.2,0.5), loc='center right', \n",
    "            bbox_transform=plt.gcf().transFigure)\n",
    "    pdf.savefig(bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # Plotting sentiments frequencies\n",
    "    plt.pie(sentiment_freq, labels=sentiment_labels, \n",
    "            startangle=90, colors=getColors(len(sentiment_labels)),\n",
    "            counterclock=False, autopct='%1.1f%%',\n",
    "            explode=[0.1 for sentiment in sentiment_labels], shadow=True)\n",
    "    plt.title('Sentiment Frequencies')\n",
    "    plt.legend(title='Sentiments:', labels=sentiment_labels, bbox_to_anchor=(1,0.5), loc='center right', bbox_transform=plt.gcf().transFigure)\n",
    "    pdf.savefig(bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Words as Features\n",
    "\n",
    "## 2.1 - Processing the dataset: Extracting tokens/words and their frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocabulary:  30449 tokens\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(posts)\n",
    "emotion_to_index = {}\n",
    "sentiment_to_index = {}\n",
    "\n",
    "# Transforming emotions to integer values\n",
    "index = 0\n",
    "for emotion in emotions:\n",
    "    if emotion in emotion_to_index:\n",
    "        # already seen\n",
    "        continue\n",
    "    emotion_to_index[emotion] = index\n",
    "    index += 1\n",
    "y_emotions = [emotion_to_index[emotion] for emotion in emotions]\n",
    "\n",
    "# Transforming sentiments to integer values\n",
    "index = 0\n",
    "for sentiment in sentiments:\n",
    "    if sentiment in sentiment_to_index:\n",
    "        continue\n",
    "    sentiment_to_index[sentiment] = index\n",
    "    index += 1\n",
    "y_sentiments = [sentiment_to_index[sentiment] for sentiment in sentiments]\n",
    "\n",
    "print('Size of vocabulary: ', len(vectorizer.vocabulary_), 'tokens')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 - Splitting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_emotions_train, y_emotions_test = train_test_split(X, y_emotions, test_size=0.2, random_state=0)\n",
    "X_train, X_test, y_sentiments_train, y_sentiments_test = train_test_split(X, y_sentiments, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 - Training and testing classifiers for both classifications, using word frequency as features\n",
    "\n",
    "### 2.3.1 - Base-MNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_MNB = MultinomialNB()\n",
    "\n",
    "base_MNB_emotions_model = base_MNB.fit(X_train, y_emotions_train)\n",
    "y_base_MNB_emotions_pred = base_MNB_emotions_model.predict(X_test)\n",
    "\n",
    "base_MNB_sentiments_model = base_MNB.fit(X_train, y_sentiments_train)\n",
    "y_base_MNB_sentiments_pred = base_MNB_sentiments_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 - Base-DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_DT = DecisionTreeClassifier()\n",
    "\n",
    "base_DT_emotions_model = base_DT.fit(X_train, y_emotions_train)\n",
    "y_base_DT_emotions_pred = base_DT_emotions_model.predict(X_test)\n",
    "\n",
    "base_DT_sentiments_model = base_DT.fit(X_train, y_sentiments_train)\n",
    "y_base_DT_sentiments_pred = base_DT_sentiments_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 - Base-MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 1 0 ... 1 0 3]\n"
     ]
    }
   ],
   "source": [
    "base_MLP = Perceptron()\n",
    "\n",
    "base_MLP_emotions_model = base_MLP.fit(X_train, y_emotions_train)\n",
    "y_base_MLP_emotions_pred = base_MLP_emotions_model.predict(X_test)\n",
    "\n",
    "base_MLP_sentiments_model = base_MLP.fit(X_train, y_sentiments_train)\n",
    "y_base_MLP_sentiments_pred = base_MLP_sentiments_model.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
