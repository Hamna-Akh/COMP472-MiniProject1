{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/juansalas/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import gzip\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim.downloader as api\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "from random import randint\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dataset Preparation & Analysis\n",
    "\n",
    "## 1.2 - Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### goemotions.json.gz must be placed in the parent of current directory\n",
    "\n",
    "path = os.getcwd()\n",
    "# f = gzip.open(os.path.abspath(os.path.join(path, os.pardir)) + '/goemotions.json.gz', 'rb')\n",
    "# file_content = f.read()\n",
    "\n",
    "# data_list = json.loads(file_content)\n",
    "\n",
    "# Uncomment code below for sample load\n",
    "f = open(os.path.abspath(os.path.join(path, os.pardir)) + '/goemotions_056.json')\n",
    "data_list = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3.1 - Extracting the posts and 2 sets of labels (emotion and sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = []\n",
    "emotions = []\n",
    "sentiments = []\n",
    "\n",
    "for entry in data_list:\n",
    "    posts.append(entry[0])\n",
    "    emotions.append(entry[1])\n",
    "    sentiments.append(entry[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3.2 - Plotting the distribution of the posts in each category and saving the graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_counts = []\n",
    "emotion_labels = []\n",
    "sentiment_counts = []\n",
    "sentiment_labels = []\n",
    "\n",
    "# Get n different colors\n",
    "def getColors(n):\n",
    "    colors = []\n",
    "    for i in range(n):\n",
    "        color = '#%06X' % randint(0, 0xFFFFFF)\n",
    "        while color in colors:\n",
    "            color = '#%06X' % randint(0, 0xFFFFFF)\n",
    "        colors.append(color)\n",
    "    return colors\n",
    "\n",
    "# Breakdown emotions list into counts and labels\n",
    "for emotion in emotions:\n",
    "    if emotion in emotion_labels:\n",
    "        index = emotion_labels.index(emotion)\n",
    "        emotion_counts[index] = emotion_counts[index] + 1\n",
    "    else:\n",
    "        emotion_labels.append(emotion)\n",
    "        emotion_counts.append(1)\n",
    "\n",
    "# Breakdown sentiments list into counts and labels\n",
    "for sentiment in sentiments:\n",
    "    if sentiment in sentiment_labels:\n",
    "        index = sentiment_labels.index(sentiment)\n",
    "        sentiment_counts[index] = sentiment_counts[index] + 1\n",
    "    else:\n",
    "        sentiment_labels.append(sentiment)\n",
    "        sentiment_counts.append(1)\n",
    "\n",
    "# Calculating frequencies for each classification\n",
    "emotion_freq = [round((count/sum(emotion_counts)), 3) for count in emotion_counts]\n",
    "sentiment_freq = [round((count/sum(sentiment_counts)), 3) for count in sentiment_counts]\n",
    "\n",
    "with PdfPages('frequency_charts.pdf') as pdf:\n",
    "    # Plotting emotion frequencies\n",
    "    plt.pie(emotion_counts, labels=emotion_labels, \n",
    "            startangle=90, colors=getColors(len(emotion_labels)),\n",
    "            rotatelabels=True, counterclock=False, \n",
    "            explode=[0.1 for emotion in emotion_labels], shadow=True)\n",
    "    plt.title('Emotion Frequencies', y=1.25)\n",
    "    # Displaying distribution in legend because hard to see on the chart    \n",
    "    plt.legend(title='Emotions:', labels=[f'{l}: {s:0.1f}%' for l, s in zip(emotion_labels, [freq * 100 for freq in emotion_freq])],\n",
    "            bbox_to_anchor=(1.2,0.5), loc='center right', \n",
    "            bbox_transform=plt.gcf().transFigure)\n",
    "    pdf.savefig(bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # Plotting sentiment frequencies\n",
    "    plt.pie(sentiment_counts, labels=sentiment_labels, \n",
    "            startangle=90, colors=getColors(len(sentiment_labels)),\n",
    "            counterclock=False, autopct='%1.1f%%',\n",
    "            explode=[0.1 for sentiment in sentiment_labels], shadow=True)\n",
    "    plt.title('Sentiment Frequencies')\n",
    "    plt.legend(title='Sentiments:', labels=sentiment_labels, bbox_to_anchor=(1,0.5), loc='center right', bbox_transform=plt.gcf().transFigure)\n",
    "    pdf.savefig(bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Words as Features\n",
    "\n",
    "## 2.1 - Processing the dataset: Extracting tokens/words and their frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocabulary:  772 tokens\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(posts)\n",
    "\n",
    "# Vectorizing emotions and sentiments\n",
    "emotion_to_index = {}\n",
    "sentiment_to_index = {}\n",
    "index = 0\n",
    "\n",
    "for emotion in emotions:\n",
    "    if emotion in emotion_to_index:\n",
    "        # already seen\n",
    "        continue\n",
    "    emotion_to_index[emotion] = index\n",
    "    index += 1\n",
    "y_emotions = [emotion_to_index[emotion] for emotion in emotions]\n",
    "\n",
    "index = 0\n",
    "for sentiment in sentiments:\n",
    "    if sentiment in sentiment_to_index:\n",
    "        continue\n",
    "    sentiment_to_index[sentiment] = index\n",
    "    index += 1\n",
    "y_sentiments = [sentiment_to_index[sentiment] for sentiment in sentiments]\n",
    "\n",
    "print('Size of vocabulary: ', len(vectorizer.vocabulary_), 'tokens')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 - Splitting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_emotions_train, y_emotions_test = train_test_split(X, y_emotions, test_size=0.2, random_state=0)\n",
    "X_train, X_test, y_sentiments_train, y_sentiments_test = train_test_split(X, y_sentiments, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 - Training and testing classifiers for both classifications, using word frequency as features\n",
    "\n",
    "### 2.3.1 - Base-MNB\n",
    "\n",
    "Training the base MNB model and saving to pickle files. *Run following code if trained model pickle files do not already exist*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_MNB = MultinomialNB()\n",
    "\n",
    "base_MNB_emotions_model = base_MNB.fit(X_train, y_emotions_train)\n",
    "with open('base_MNB_emotions_model.pkl', 'wb') as file:\n",
    "    pickle.dump(base_MNB_emotions_model, file)\n",
    "\n",
    "base_MNB_sentiments_model = base_MNB.fit(X_train, y_sentiments_train)\n",
    "with open('base_MNB_sentiments_model.pkl', 'wb') as file:\n",
    "    pickle.dump(base_MNB_sentiments_model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting the trained base MNB models for emotions and sentiments. *Run following code if trained model pickle files exist*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('base_MNB_emotions_model.pkl', 'rb') as file:\n",
    "    base_MNB_emotions_model = pickle.load(file)\n",
    "    y_base_MNB_emotions_pred = base_MNB_emotions_model.predict(X_test)\n",
    "\n",
    "    # 2.4 Classification Performance\n",
    "    f = open('base_MNB_emotions_performance.txt', 'w')\n",
    "    f.write('Base MNB Performance for emotions\\n')\n",
    "    f.write('---------------------------------\\n')\n",
    "    f.write('Hyper-parameters: ')\n",
    "    f.write(str(base_MNB_emotions_model.get_params()))\n",
    "    f.write('\\n\\nConfusion matrix:\\n')\n",
    "    f.write(str(confusion_matrix(y_emotions_test, y_base_MNB_emotions_pred)))\n",
    "    f.write('\\n\\nClassification report:\\n')\n",
    "    f.write(str(classification_report(y_emotions_test, y_base_MNB_emotions_pred)))\n",
    "    f.close()\n",
    "\n",
    "with open('base_MNB_sentiments_model.pkl', 'rb') as file:\n",
    "    base_MNB_sentiments_model = pickle.load(file)\n",
    "    y_base_MNB_sentiments_pred = base_MNB_sentiments_model.predict(X_test)\n",
    "\n",
    "    # 2.4 Classification Performance\n",
    "    f = open('base_MNB_sentiments_performance.txt', 'w')\n",
    "    f.write('Base MNB Performance for sentiments\\n')\n",
    "    f.write('---------------------------------\\n')\n",
    "    f.write('Hyper-parameters: ')\n",
    "    f.write(str(base_MNB_sentiments_model.get_params()))\n",
    "    f.write('\\n\\nConfusion matrix:\\n')\n",
    "    f.write(str(confusion_matrix(y_sentiments_test, y_base_MNB_sentiments_pred)))\n",
    "    f.write('\\n\\nClassification report:\\n')\n",
    "    f.write(str(classification_report(y_sentiments_test, y_base_MNB_sentiments_pred)))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 - Base-DT\n",
    "\n",
    "Training the base DT model and saving to pickle files. *Run following code if trained model pickle files do not already exist*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_DT = DecisionTreeClassifier()\n",
    "\n",
    "base_DT_emotions_model = base_DT.fit(X_train, y_emotions_train)\n",
    "with open('base_DT_emotions_model.pkl', 'wb') as file:\n",
    "    pickle.dump(base_DT_emotions_model, file)\n",
    "\n",
    "base_DT_sentiments_model = base_DT.fit(X_train, y_sentiments_train)\n",
    "with open('base_DT_sentiments_model.pkl', 'wb') as file:\n",
    "    pickle.dump(base_DT_sentiments_model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting the trained base DT models for emotions and sentiments. *Run following code if trained model pickle files exist*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "with open('base_DT_emotions_model.pkl', 'rb') as file:\n",
    "    base_DT_emotions_model = pickle.load(file)\n",
    "    y_base_DT_emotions_pred = base_DT_emotions_model.predict(X_test)\n",
    "\n",
    "    # 2.4 Classification Performance\n",
    "    f = open('base_DT_emotions_performance.txt', 'w')\n",
    "    f.write('Base DT Performance for emotions\\n')\n",
    "    f.write('---------------------------------\\n')\n",
    "    f.write('Hyper-parameters: ')\n",
    "    f.write(str(base_DT_emotions_model.get_params()))\n",
    "    f.write('\\n\\nConfusion matrix:\\n')\n",
    "    f.write(str(confusion_matrix(y_emotions_test, y_base_DT_emotions_pred)))\n",
    "    f.write('\\n\\nClassification report:\\n')\n",
    "    f.write(str(classification_report(y_emotions_test, y_base_DT_emotions_pred)))\n",
    "    f.close()\n",
    "\n",
    "with open('base_DT_sentiments_model.pkl', 'rb') as file:\n",
    "    base_DT_sentiments_model = pickle.load(file)\n",
    "    y_base_DT_sentiments_pred = base_DT_sentiments_model.predict(X_test)\n",
    "\n",
    "    # 2.4 Classification Performance\n",
    "    f = open('base_DT_sentiments_performance.txt', 'w')\n",
    "    f.write('Base DT Performance for sentiments\\n')\n",
    "    f.write('---------------------------------\\n')\n",
    "    f.write('Hyper-parameters: ')\n",
    "    f.write(str(base_DT_sentiments_model.get_params()))\n",
    "    f.write('\\n\\nConfusion matrix:\\n')\n",
    "    f.write(str(confusion_matrix(y_sentiments_test, y_base_DT_sentiments_pred)))\n",
    "    f.write('\\n\\nClassification report:\\n')\n",
    "    f.write(str(classification_report(y_sentiments_test, y_base_DT_sentiments_pred)))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 - Base-MLP\n",
    "\n",
    "Training the base MLP model and saving to pickle files. *Run following code if trained model pickle files do not already exist*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_MLP = MLPClassifier(max_iter=2000)\n",
    "\n",
    "base_MLP_emotions_model = base_MLP.fit(X_train, y_emotions_train)\n",
    "with open('base_MLP_emotions_model.pkl', 'wb') as file:\n",
    "    pickle.dump(base_MLP_emotions_model, file)\n",
    "\n",
    "base_MLP_sentiments_model = base_MLP.fit(X_train, y_sentiments_train)\n",
    "with open('base_MLP_sentiments_model.pkl', 'wb') as file:\n",
    "    pickle.dump(base_MLP_sentiments_model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting the trained base MLP models for emotions and sentiments. *Run following code if trained model pickle files exist*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('base_MLP_emotions_model.pkl', 'rb') as file:\n",
    "    base_MLP_emotions_model = pickle.load(file)\n",
    "    y_base_MLP_emotions_pred = base_MLP_emotions_model.predict(X_test)\n",
    "\n",
    "    # 2.4 Classification Performance\n",
    "    f = open('base_MLP_emotions_performance.txt', 'w')\n",
    "    f.write('Base MLP Performance for emotions\\n')\n",
    "    f.write('---------------------------------\\n')\n",
    "    f.write('Hyper-parameters: ')\n",
    "    f.write(str(base_MLP_emotions_model.get_params()))\n",
    "    f.write('\\n\\nConfusion matrix:\\n')\n",
    "    f.write(str(confusion_matrix(y_emotions_test, y_base_MLP_emotions_pred)))\n",
    "    f.write('\\n\\nClassification report:\\n')\n",
    "    f.write(str(classification_report(y_emotions_test, y_base_MLP_emotions_pred)))\n",
    "    f.close()\n",
    "\n",
    "with open('base_MLP_sentiments_model.pkl', 'rb') as file:\n",
    "    base_MLP_sentiments_model = pickle.load(file)\n",
    "    y_base_MLP_sentiments_pred = base_MLP_sentiments_model.predict(X_test)\n",
    "\n",
    "    # 2.4 Classification Performance\n",
    "    f = open('base_MLP_sentiments_performance.txt', 'w')\n",
    "    f.write('Base MLP Performance for sentiments\\n')\n",
    "    f.write('---------------------------------\\n')\n",
    "    f.write('Hyper-parameters: ')\n",
    "    f.write(str(base_MLP_sentiments_model.get_params()))\n",
    "    f.write('\\n\\nConfusion matrix:\\n')\n",
    "    f.write(str(confusion_matrix(y_sentiments_test, y_base_MLP_sentiments_pred)))\n",
    "    f.write('\\n\\nClassification report:\\n')\n",
    "    f.write(str(classification_report(y_sentiments_test, y_base_MLP_sentiments_pred)))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.4 - Top-MNB\n",
    "\n",
    "Training the top MNB model and saving to pickle files. *Run following code if trained model pickle files do not already exist*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_MNB_hyper_params = {\n",
    "    # Because an alpha too small will result in numeric errors, 0 is set as 1.0e-10\n",
    "    'alpha': [1.0e-10, 0.5, 1.5, 3.0]\n",
    "}\n",
    "\n",
    "# FOR SAMPLE DATASET: Removes the frequencies of the emotions not found in the training set\n",
    "sample_emotions_freq = []\n",
    "for idx, freq in enumerate(emotion_freq):\n",
    "    if list(set(y_emotions_train)).count(idx) > 0:\n",
    "        sample_emotions_freq.append(freq)\n",
    "\n",
    "top_MNB_emotions = MultinomialNB(class_prior=sample_emotions_freq)\n",
    "top_MNB_sentiments = MultinomialNB(class_prior=sentiment_freq)\n",
    "\n",
    "top_MNB_emotions_grid_search = GridSearchCV(estimator=top_MNB_emotions, param_grid=top_MNB_hyper_params)\n",
    "top_MNB_sentiments_grid_search = GridSearchCV(estimator=top_MNB_sentiments, param_grid=top_MNB_hyper_params)\n",
    "\n",
    "top_MNB_emotions_model = top_MNB_emotions_grid_search.fit(X_train, y_emotions_train)\n",
    "with open('top_MNB_emotions_model.pkl', 'wb') as file:\n",
    "    pickle.dump(top_MNB_emotions_model, file)\n",
    "\n",
    "top_MNB_sentiments_model = top_MNB_sentiments_grid_search.fit(X_train, y_sentiments_train)\n",
    "with open('top_MNB_sentiments_model.pkl', 'wb') as file:\n",
    "    pickle.dump(top_MNB_sentiments_model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting the trained top MNB models for emotions and sentiments. *Run following code if trained model pickle files exist*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('top_MNB_emotions_model.pkl', 'rb') as file:\n",
    "    top_MNB_emotions_model = pickle.load(file)\n",
    "    y_top_MNB_emotions_pred = top_MNB_emotions_model.predict(X_test)\n",
    "\n",
    "    # 2.4 Classification Performance\n",
    "    f = open('top_MNB_emotions_performance.txt', 'w')\n",
    "    f.write('Base MLP Performance for emotions\\n')\n",
    "    f.write('---------------------------------\\n')\n",
    "    f.write('Hyper-parameters: ')\n",
    "    f.write(str(top_MNB_emotions_model.get_params()))\n",
    "    f.write('\\n\\nBest parameters: ')\n",
    "    f.write(str(top_MNB_emotions_model.best_params_))\n",
    "    f.write('\\n\\nConfusion matrix:\\n')\n",
    "    f.write(str(confusion_matrix(y_emotions_test, y_top_MNB_emotions_pred)))\n",
    "    f.write('\\n\\nClassification report:\\n')\n",
    "    f.write(str(classification_report(y_emotions_test, y_top_MNB_emotions_pred)))\n",
    "    f.close()\n",
    "\n",
    "with open('top_MNB_sentiments_model.pkl', 'rb') as file:\n",
    "    top_MNB_sentiments_model = pickle.load(file)\n",
    "    y_top_MNB_sentiments_pred = top_MNB_sentiments_model.predict(X_test)\n",
    "\n",
    "    # 2.4 Classification Performance\n",
    "    f = open('top_MNB_sentiments_performance.txt', 'w')\n",
    "    f.write('Base MLP Performance for sentiments\\n')\n",
    "    f.write('---------------------------------\\n')\n",
    "    f.write('Hyper-parameters: ')\n",
    "    f.write(str(top_MNB_sentiments_model.get_params()))\n",
    "    f.write('\\n\\nBest parameters: ')\n",
    "    f.write(str(top_MNB_sentiments_model.best_params_))\n",
    "    f.write('\\n\\nConfusion matrix:\\n')\n",
    "    f.write(str(confusion_matrix(y_sentiments_test, y_top_MNB_sentiments_pred)))\n",
    "    f.write('\\n\\nClassification report:\\n')\n",
    "    f.write(str(classification_report(y_sentiments_test, y_top_MNB_sentiments_pred)))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.5 - Top-DT\n",
    "\n",
    "Training the top DT model and saving to pickle files. *Run following code if trained model pickle files do not already exist*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/model_selection/_split.py:684: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "top_DT_hyper_params = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [5, 10],\n",
    "    'min_samples_split': [2, 3, 4]\n",
    "}\n",
    "\n",
    "top_DT = DecisionTreeClassifier()\n",
    "top_DT_grid_search = GridSearchCV(estimator=top_DT, param_grid=top_DT_hyper_params)\n",
    "\n",
    "top_DT_emotions_model = top_DT_grid_search.fit(X_train, y_emotions_train)\n",
    "with open('top_DT_emotions_model.pkl', 'wb') as file:\n",
    "    pickle.dump(top_DT_emotions_model, file)\n",
    "\n",
    "top_DT_sentiments_model = top_DT_grid_search.fit(X_train, y_sentiments_train)\n",
    "with open('top_DT_sentiments_model.pkl', 'wb') as file:\n",
    "    pickle.dump(top_DT_sentiments_model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting the trained top DT models for emotions and sentiments. *Run following code if trained model pickle files exist*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "with open('top_DT_emotions_model.pkl', 'rb') as file:\n",
    "    top_DT_emotions_model = pickle.load(file)\n",
    "    y_top_DT_emotions_pred = top_DT_emotions_model.predict(X_test)\n",
    "\n",
    "    # 2.4 Classification Performance\n",
    "    f = open('top_DT_emotions_performance.txt', 'w')\n",
    "    f.write('Base MLP Performance for emotions\\n')\n",
    "    f.write('---------------------------------\\n')\n",
    "    f.write('Hyper-parameters: ')\n",
    "    f.write(str(top_DT_emotions_model.get_params()))\n",
    "    f.write('\\n\\nBest parameters: ')\n",
    "    f.write(str(top_DT_emotions_model.best_params_))\n",
    "    f.write('\\n\\nConfusion matrix:\\n')\n",
    "    f.write(str(confusion_matrix(y_emotions_test, y_top_DT_emotions_pred)))\n",
    "    f.write('\\n\\nClassification report:\\n')\n",
    "    f.write(str(classification_report(y_emotions_test, y_top_DT_emotions_pred)))\n",
    "    f.close()\n",
    "\n",
    "with open('top_DT_sentiments_model.pkl', 'rb') as file:\n",
    "    top_DT_sentiments_model = pickle.load(file)\n",
    "    y_top_DT_sentiments_pred = top_DT_sentiments_model.predict(X_test)\n",
    "\n",
    "    # 2.4 Classification Performance\n",
    "    f = open('top_DT_sentiments_performance.txt', 'w')\n",
    "    f.write('Base MLP Performance for sentiments\\n')\n",
    "    f.write('---------------------------------\\n')\n",
    "    f.write('Hyper-parameters: ')\n",
    "    f.write(str(top_DT_sentiments_model.get_params()))\n",
    "    f.write('\\n\\nBest parameters: ')\n",
    "    f.write(str(top_DT_sentiments_model.best_params_))\n",
    "    f.write('\\n\\nConfusion matrix:\\n')\n",
    "    f.write(str(confusion_matrix(y_sentiments_test, y_top_DT_sentiments_pred)))\n",
    "    f.write('\\n\\nClassification report:\\n')\n",
    "    f.write(str(classification_report(y_sentiments_test, y_top_DT_sentiments_pred)))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.6 - Top-MLP\n",
    "\n",
    "Training the top MLP model and saving to pickle files. *Run following code if trained model pickle files do not already exist*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_MLP_hyper_params = {\n",
    "    'activation': ['logistic', 'tanh', 'relu', 'identity'],\n",
    "    'hidden_layer_sizes': [(30, 50), (10, 10, 10)],\n",
    "    'solver': ['adam', 'sgd']\n",
    "}\n",
    "\n",
    "top_MLP = MLPClassifier(max_iter=100)\n",
    "top_MLP_grid_search = GridSearchCV(estimator=top_MLP, param_grid=top_MLP_hyper_params)\n",
    "\n",
    "top_MLP_emotions_model = top_MLP_grid_search.fit(X_train, y_emotions_train)\n",
    "with open('top_MLP_emotions_model.pkl', 'wb') as file:\n",
    "    pickle.dump(top_MLP_emotions_model, file)\n",
    "\n",
    "top_MLP_sentiments_model = top_MLP_grid_search.fit(X_train, y_sentiments_train)\n",
    "with open('top_MLP_sentiments_model.pkl', 'wb') as file:\n",
    "    pickle.dump(top_MLP_sentiments_model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting the trained top MLP models for emotions and sentiments. *Run following code if trained model pickle files exist*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('top_MLP_emotions_model.pkl', 'rb') as file:\n",
    "    top_MLP_emotions_model = pickle.load(file)\n",
    "    y_top_MLP_emotions_pred = top_MLP_emotions_model.predict(X_test)\n",
    "\n",
    "    # 2.4 Classification Performance\n",
    "    f = open('top_MLP_emotions_performance.txt', 'w')\n",
    "    f.write('Base MLP Performance for emotions\\n')\n",
    "    f.write('---------------------------------\\n')\n",
    "    f.write('Hyper-parameters: ')\n",
    "    f.write(str(top_MLP_emotions_model.get_params()))\n",
    "    f.write('\\n\\nBest parameters: ')\n",
    "    f.write(str(top_MLP_emotions_model.best_params_))\n",
    "    f.write('\\n\\nConfusion matrix:\\n')\n",
    "    f.write(str(confusion_matrix(y_emotions_test, y_top_MLP_emotions_pred)))\n",
    "    f.write('\\n\\nClassification report:\\n')\n",
    "    f.write(str(classification_report(y_emotions_test, y_top_MLP_emotions_pred)))\n",
    "    f.close()\n",
    "\n",
    "with open('top_MLP_sentiments_model.pkl', 'rb') as file:\n",
    "    top_MLP_sentiments_model = pickle.load(file)\n",
    "    y_top_MLP_sentiments_pred = top_MLP_sentiments_model.predict(X_test)\n",
    "\n",
    "    # 2.4 Classification Performance\n",
    "    f = open('top_MLP_sentiments_performance.txt', 'w')\n",
    "    f.write('Base MLP Performance for sentiments\\n')\n",
    "    f.write('---------------------------------\\n')\n",
    "    f.write('Hyper-parameters: ')\n",
    "    f.write(str(top_MLP_sentiments_model.get_params()))\n",
    "    f.write('\\n\\nBest parameters: ')\n",
    "    f.write(str(top_MLP_sentiments_model.best_params_))\n",
    "    f.write('\\n\\nConfusion matrix:\\n')\n",
    "    f.write(str(confusion_matrix(y_sentiments_test, y_top_MLP_sentiments_pred)))\n",
    "    f.write('\\n\\nClassification report:\\n')\n",
    "    f.write(str(classification_report(y_sentiments_test, y_top_MLP_sentiments_pred)))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 - Classification Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: We generated individual performance files, rather than one single performance files each of the 6 classifiers for both the emotion and sentiment classifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 - Different train and test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_emotions_train, X2_emotions_test, y2_emotions_train, y2_emotions_test = train_test_split(X, y_emotions, test_size=0.2, random_state=0)\n",
    "X2_sentiments_train, X2_sentiments_test, y2_sentiments_train, y2_sentiments_test = train_test_split(X, y_sentiments, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3_emotions_train, X3_emotions_test, y3_emotions_train, y3_emotions_test = train_test_split(X, y_emotions, test_size=0.2, random_state=1)\n",
    "X3_sentiments_train, X3_sentiments_test, y3_sentiments_train, y3_sentiments_test = train_test_split(X, y_sentiments, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.1 - Base MNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base2_MNB_emotions_model = base_MNB.fit(X2_emotions_train, y2_emotions_train)\n",
    "y2_base_MNB_emotions_pred = base2_MNB_emotions_model.predict(X2_emotions_test)\n",
    "\n",
    "base2_MNB_sentiments_model = base_MNB.fit(X2_sentiments_train, y2_sentiments_train)\n",
    "y2_base_MNB_sentiments_pred = base2_MNB_sentiments_model.predict(X2_sentiments_test)\n",
    "\n",
    "print(\"Random State = 0: Base-MNB with the default parameters\")\n",
    "\n",
    "# evaluate classifier\n",
    "print(\"\\nBase-MNB Emotions Classification Report:\\n\", classification_report(y2_emotions_test, y2_base_MNB_emotions_pred))\n",
    "print(\"\\nBase-MNB Sentiments Classification Report:\\n\", classification_report(y2_sentiments_test, y2_base_MNB_sentiments_pred))\n",
    "\n",
    "# show confusion Matrix\n",
    "print(\"\\nBase-MNB Emotions Confusion Matrix:\\n\", confusion_matrix(y2_emotions_test, y2_base_MNB_emotions_pred))\n",
    "print(\"\\nBase-MNB Sentiments Confusion Matrix:\\n\", confusion_matrix(y2_sentiments_test, y2_base_MNB_sentiments_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base3_MNB_emotions_model = base_MNB.fit(X3_emotions_train, y3_emotions_train)\n",
    "y3_base_MNB_emotions_pred = base3_MNB_emotions_model.predict(X3_emotions_test)\n",
    "\n",
    "base3_MNB_sentiments_model = base_MNB.fit(X3_sentiments_train, y3_sentiments_train)\n",
    "y3_base_MNB_sentiments_pred = base3_MNB_sentiments_model.predict(X3_sentiments_test)\n",
    "\n",
    "print(\"Random State = 1: Base-MNB with the default parameters\")\n",
    "\n",
    "# evaluate classifier\n",
    "print(\"\\nBase-MNB Emotions Classification Report:\\n\", classification_report(y3_emotions_test, y3_base_MNB_emotions_pred))\n",
    "print(\"\\nBase-MNB Sentiments Classification Report:\\n\", classification_report(y3_sentiments_test, y3_base_MNB_sentiments_pred))\n",
    "\n",
    "# show confusion Matrix\n",
    "print(\"\\nBase-MNB Emotions Confusion Matrix:\\n\", confusion_matrix(y3_emotions_test, y3_base_MNB_emotions_pred))\n",
    "print(\"\\nBase-MNB Sentiments Confusion Matrix:\\n\", confusion_matrix(y3_sentiments_test, y3_base_MNB_sentiments_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.2 - Base DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base2_DT_emotions_model = base_DT.fit(X2_emotions_train, y2_emotions_train)\n",
    "y2_base_DT_emotions_pred = base2_DT_emotions_model.predict(X2_emotions_test)\n",
    "\n",
    "base2_DT_sentiments_model = base_DT.fit(X2_sentiments_train, y2_sentiments_train)\n",
    "y2_base_DT_sentiments_pred = base2_DT_sentiments_model.predict(X2_sentiments_test)\n",
    "\n",
    "print(\"Random State = 0: Base-DT with the default parameters\")\n",
    "\n",
    "# evaluate classifier\n",
    "print(\"\\nBase-DT Emotions Classification Report:\\n\", classification_report(y2_emotions_test, y2_base_DT_emotions_pred))\n",
    "print(\"\\nBase-DT Sentiments Classification Report:\\n\", classification_report(y2_sentiments_test, y2_base_DT_sentiments_pred))\n",
    "\n",
    "# show confusion Matrix\n",
    "print(\"\\nBase-DT Emotions Confusion Matrix:\\n\", confusion_matrix(y2_emotions_test, y2_base_DT_emotions_pred))\n",
    "print(\"\\nBase-DT Sentiments Confusion Matrix:\\n\", confusion_matrix(y2_sentiments_test, y2_base_DT_sentiments_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base3_DT_emotions_model = base_DT.fit(X3_emotions_train, y3_emotions_train)\n",
    "y3_base_DT_emotions_pred = base3_DT_emotions_model.predict(X3_emotions_test)\n",
    "\n",
    "base3_DT_sentiments_model = base_DT.fit(X2_sentiments_train, y3_sentiments_train)\n",
    "y3_base_DT_sentiments_pred = base3_DT_sentiments_model.predict(X3_sentiments_test)\n",
    "\n",
    "print(\"Random State = 1: Base-DT with the default parameters\")\n",
    "\n",
    "# evaluate classifier\n",
    "print(\"\\nBase-DT Emotions Classification Report:\\n\", classification_report(y3_emotions_test, y3_base_DT_emotions_pred))\n",
    "print(\"\\nBase-DT Sentiments Classification Report:\\n\", classification_report(y3_sentiments_test, y3_base_DT_sentiments_pred))\n",
    "\n",
    "# show confusion Matrix\n",
    "print(\"\\nBase-DT Emotions Confusion Matrix:\\n\", confusion_matrix(y3_emotions_test, y3_base_DT_emotions_pred))\n",
    "print(\"\\nBase-DT Sentiments Confusion Matrix:\\n\", confusion_matrix(y3_sentiments_test, y3_base_DT_sentiments_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.3 - Base MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base2_MLP_emotions_model = base_MLP.fit(X2_emotions_train, y2_emotions_train)\n",
    "y2_base_MLP_emotions_pred = base2_MLP_emotions_model.predict(X2_emotions_test)\n",
    "\n",
    "base2_MLP_sentiments_model = base_MLP.fit(X2_sentiments_train, y2_sentiments_train)\n",
    "y2_base_MLP_sentiments_pred = base2_MLP_sentiments_model.predict(X2_sentiments_test)\n",
    "\n",
    "print(\"Random State = 0: Base-MLP with the default parameters\")\n",
    "\n",
    "# evaluate classifier\n",
    "print(\"\\nBase-MLP Emotions Classification Report:\\n\", classification_report(y2_emotions_test, y2_base_MLP_emotions_pred))\n",
    "print(\"\\nBase-MLP Sentiments Classification Report:\\n\", classification_report(y2_sentiments_test, y2_base_MLP_sentiments_pred))\n",
    "\n",
    "# show confusion Matrix\n",
    "print(\"\\nBase-MLP Emotions Confusion Matrix:\\n\", confusion_matrix(y2_emotions_test, y2_base_MLP_emotions_pred))\n",
    "print(\"\\nBase-MLP Sentiments Confusion Matrix:\\n\", confusion_matrix(y2_sentiments_test, y2_base_MLP_sentiments_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base3_MLP_emotions_model = base_MLP.fit(X3_emotions_train, y3_emotions_train)\n",
    "y3_base_MLP_emotions_pred = base3_MLP_emotions_model.predict(X3_emotions_test)\n",
    "\n",
    "base3_MLP_sentiments_model = base_MLP.fit(X3_sentiments_train, y3_sentiments_train)\n",
    "y3_base_MLP_sentiments_pred = base3_MLP_sentiments_model.predict(X3_sentiments_test)\n",
    "\n",
    "print(\"Random State = 1: Base-MLP with the default parameters\")\n",
    "\n",
    "# evaluate classifier\n",
    "print(\"\\nBase-MLP Emotions Classification Report:\\n\", classification_report(y3_emotions_test, y3_base_MLP_emotions_pred))\n",
    "print(\"\\nBase-MLP Sentiments Classification Report:\\n\", classification_report(y3_sentiments_test, y3_base_MLP_sentiments_pred))\n",
    "\n",
    "# show confusion Matrix\n",
    "print(\"\\nBase-MLP Emotions Confusion Matrix:\\n\", confusion_matrix(y3_emotions_test, y3_base_MLP_emotions_pred))\n",
    "print(\"\\nBase-MLP Sentiments Confusion Matrix:\\n\", confusion_matrix(y3_sentiments_test, y3_base_MLP_sentiments_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.4 - Top MNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top2_MNB_hyper_params = {\n",
    "    # Because an alpha too small will result in numeric errors, 0 is set as 1.0e-10\n",
    "    'alpha': [1.0e-10, 0.5, 1.5, 3.0]\n",
    "}\n",
    "\n",
    "print(\"Random State = 0: Top-MNB with the default parameters\")\n",
    "\n",
    "# FOR SAMPLE DATASET: Removes the frequencies of the emotions not found in the training set\n",
    "sample_emotions_freq = []\n",
    "for idx, freq in enumerate(emotion_freq):\n",
    "    if list(set(y2_emotions_train)).count(idx) > 0:\n",
    "        sample_emotions_freq.append(freq)\n",
    "\n",
    "top2_MNB_emotions = MultinomialNB(class_prior=sample_emotions_freq)\n",
    "top2_MNB_sentiments = MultinomialNB(class_prior=sentiment_freq)\n",
    "\n",
    "top2_MNB_emotions_grid_search = GridSearchCV(estimator=top2_MNB_emotions, param_grid=top2_MNB_hyper_params)\n",
    "top2_MNB_sentiments_grid_search = GridSearchCV(estimator=top2_MNB_sentiments, param_grid=top2_MNB_hyper_params)\n",
    "\n",
    "top2_MNB_emotions_model = top2_MNB_emotions_grid_search.fit(X2_emotions_train, y2_emotions_train)\n",
    "y2_top_MNB_emotions_pred = top2_MNB_emotions_model.predict(X2_emotions_test)\n",
    "print('best params for emotions MNB: ', top_MNB_emotions_model.best_params_)\n",
    "\n",
    "top2_MNB_sentiments_model = top2_MNB_sentiments_grid_search.fit(X2_sentiments_train, y2_sentiments_train)\n",
    "y2_top_MNB_sentiments_pred = top2_MNB_sentiments_model.predict(X2_sentiments_test)\n",
    "print('best params for sentiments MNB: ', top_MNB_sentiments_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top3_MNB_hyper_params = {\n",
    "    # Because an alpha too small will result in numeric errors, 0 is set as 1.0e-10\n",
    "    'alpha': [1.0e-10, 0.5, 1.5, 3.0]\n",
    "}\n",
    "\n",
    "print(\"Random State = 1: Top-MNB with the default parameters\")\n",
    "\n",
    "# FOR SAMPLE DATASET: Removes the frequencies of the emotions not found in the training set\n",
    "sample_emotions_freq = []\n",
    "for idx, freq in enumerate(emotion_freq):\n",
    "    if list(set(y3_emotions_train)).count(idx) > 0:\n",
    "        sample_emotions_freq.append(freq)\n",
    "\n",
    "top3_MNB_emotions = MultinomialNB(class_prior=sample_emotions_freq)\n",
    "top3_MNB_sentiments = MultinomialNB(class_prior=sentiment_freq)\n",
    "\n",
    "top3_MNB_emotions_grid_search = GridSearchCV(estimator=top3_MNB_emotions, param_grid=top3_MNB_hyper_params)\n",
    "top3_MNB_sentiments_grid_search = GridSearchCV(estimator=top3_MNB_sentiments, param_grid=top3_MNB_hyper_params)\n",
    "\n",
    "top3_MNB_emotions_model = top3_MNB_emotions_grid_search.fit(X3_emotions_train, y3_emotions_train)\n",
    "y3_top_MNB_emotions_pred = top3_MNB_emotions_model.predict(X3_emotions_test)\n",
    "print('best params for emotions MNB: ', top_MNB_emotions_model.best_params_)\n",
    "\n",
    "top3_MNB_sentiments_model = top3_MNB_sentiments_grid_search.fit(X3_sentiments_train, y3_sentiments_train)\n",
    "y3_top_MNB_sentiments_pred = top3_MNB_sentiments_model.predict(X3_sentiments_test)\n",
    "print('best params for sentiments MNB: ', top_MNB_sentiments_model.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.5 - Top DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top2_DT_hyper_params = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [5, 10],\n",
    "    'min_samples_split': [2, 3, 4]\n",
    "}\n",
    "\n",
    "print(\"Random State = 0: Top-DT with the default parameters\")\n",
    "\n",
    "top2_DT = DecisionTreeClassifier()\n",
    "top2_DT_grid_search = GridSearchCV(estimator=top_DT, param_grid=top2_DT_hyper_params)\n",
    "\n",
    "top2_DT_emotions_model = top2_DT_grid_search.fit(X2_emotions_train, y2_emotions_train)\n",
    "y2_top_DT_emotions_pred = top2_DT_emotions_model.predict(X2_emotions_test)\n",
    "\n",
    "top2_DT_sentiments_model = top2_DT_grid_search.fit(X2_sentiments_train, y2_sentiments_train)\n",
    "y2_top_DT_sentiments_pred = top2_DT_sentiments_model.predict(X2_sentiments_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top3_DT_hyper_params = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [5, 10],\n",
    "    'min_samples_split': [2, 3, 4]\n",
    "}\n",
    "\n",
    "print(\"Random State = 1: Top-DT with the default parameters\")\n",
    "\n",
    "top3_DT = DecisionTreeClassifier()\n",
    "top3_DT_grid_search = GridSearchCV(estimator=top_DT, param_grid=top3_DT_hyper_params)\n",
    "\n",
    "top3_DT_emotions_model = top3_DT_grid_search.fit(X3_emotions_train, y3_emotions_train)\n",
    "y3_top_DT_emotions_pred = top3_DT_emotions_model.predict(X3_emotions_test)\n",
    "\n",
    "top3_DT_sentiments_model = top3_DT_grid_search.fit(X3_sentiments_train, y3_sentiments_train)\n",
    "y3_top_DT_sentiments_pred = top3_DT_sentiments_model.predict(X3_sentiments_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.6 - Top MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top2_MLP_hyper_params = {\n",
    "    'activation': ['logistic', 'tanh', 'relu', 'identity'],\n",
    "    'hidden_layer_sizes': [(30, 50), (10, 10, 10)],\n",
    "    'solver': ['adam', 'sgd']\n",
    "}\n",
    "\n",
    "print(\"Random State = 0: Top-MLP with the default parameters\")\n",
    "\n",
    "top2_MLP = MLPClassifier(max_iter=1) ### talk about low epochs in analysis\n",
    "top2_MLP_grid_search = GridSearchCV(estimator=top_MLP, param_grid=top2_MLP_hyper_params)\n",
    "\n",
    "top2_MLP_emotions_model = top2_MLP_grid_search.fit(X2_emotions_train, y2_emotions_train)\n",
    "y2_top_MLP_emotions_pred = top2_MLP_emotions_model.predict(X2_emotions_test)\n",
    "\n",
    "top2_MLP_sentiments_model = top2_MLP_grid_search.fit(X2_sentiments_train, y2_sentiments_train)\n",
    "y2_top_MLP_sentiments_pred = top2_MLP_sentiments_model.predict(X2_sentiments_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top3_MLP_hyper_params = {\n",
    "    'activation': ['logistic', 'tanh', 'relu', 'identity'],\n",
    "    'hidden_layer_sizes': [(30, 50), (10, 10, 10)],\n",
    "    'solver': ['adam', 'sgd']\n",
    "}\n",
    "\n",
    "print(\"Random State = 1: Top-MLP with the default parameters\")\n",
    "\n",
    "top3_MLP = MLPClassifier(max_iter=1) ### talk about low epochs in analysis\n",
    "top3_MLP_grid_search = GridSearchCV(estimator=top_MLP, param_grid=top3_MLP_hyper_params)\n",
    "\n",
    "top3_MLP_emotions_model = top3_MLP_grid_search.fit(X3_emotions_train, y3_emotions_train)\n",
    "y3_top_MLP_emotions_pred = top3_MLP_emotions_model.predict(X3_emotions_test)\n",
    "\n",
    "top3_MLP_sentiments_model = top3_MLP_grid_search.fit(X3_sentiments_train, y3_sentiments_train)\n",
    "y3_top_MLP_sentiments_pred = top3_MLP_sentiments_model.predict(X3_sentiments_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Embeddings as Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 - Load embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GoogleNews = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 - Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_train, posts_test, post_emotions_train, post_emotions_test = train_test_split(posts, y_emotions, test_size=0.2, random_state=0)\n",
    "posts_train, posts_test, post_sentiments_train, post_sentiments_test = train_test_split(posts, y_sentiments, test_size=0.2, random_state=0)\n",
    "\n",
    "tokens = []\n",
    "for i in posts_train:\n",
    "    post_tokens = word_tokenize(i)\n",
    "    for token in post_tokens:\n",
    "        tokens.append(token)\n",
    "\n",
    "print('Size of training set vocabulary: ', len(tokens), 'tokens')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 - Average Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_embeddings = []\n",
    "\n",
    "for post in posts:\n",
    "    post_tokens = word_tokenize(post)\n",
    "    word_embeddings = []\n",
    "\n",
    "    for token in post_tokens:\n",
    "        try:\n",
    "            word_embedding = GoogleNews[token]\n",
    "            word_embeddings.append(word_embedding)\n",
    "        except KeyError: # If token is not present in Word2Vec model\n",
    "            continue\n",
    "\n",
    "    post_embedding = np.nanmean(word_embeddings)\n",
    "    post_embeddings.append(post_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 - Hit Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_counter = 0\n",
    "embedding_counter = 0\n",
    "\n",
    "for post in posts_train:\n",
    "    post_tokens = word_tokenize(post)\n",
    "    word_embeddings = []\n",
    "    \n",
    "    for token in post_tokens:\n",
    "        token_counter += 1\n",
    "        try:\n",
    "            word_embedding = GoogleNews[token]\n",
    "            word_embeddings.append(word_embedding)\n",
    "            embedding_counter += 1\n",
    "        except KeyError: # If token is not present in Word2Vec model\n",
    "            continue\n",
    "\n",
    "train_hit_rate = 100 * (embedding_counter/token_counter)\n",
    "print(train_hit_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_counter = 0\n",
    "embedding_counter = 0\n",
    "\n",
    "for post in posts_test:\n",
    "    post_tokens = word_tokenize(post)\n",
    "    word_embeddings = []\n",
    "    \n",
    "    for token in post_tokens:\n",
    "        token_counter += 1\n",
    "        try:\n",
    "            word_embedding = GoogleNews[token]\n",
    "            word_embeddings.append(word_embedding)\n",
    "            embedding_counter += 1\n",
    "        except KeyError: # If token is not present in Word2Vec model\n",
    "            continue\n",
    "\n",
    "test_hit_rate = 100 * (embedding_counter/token_counter)\n",
    "print(test_hit_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train_test_split of vector embeddings of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_embeddings = np.array(post_embeddings).reshape(-1, 1)\n",
    "\n",
    "embeddings_train, embeddings_test, embedding_emotions_train, embedding_emotions_test = train_test_split(post_embeddings, y_emotions, test_size=0.2, random_state=0)\n",
    "embeddings_train, embeddings_test, embedding_sentiments_train, embedding_sentiments_test = train_test_split(post_embeddings, y_sentiments, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 - Base MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_base_MLP = MLPClassifier(max_iter=1)\n",
    "\n",
    "embedding_base_MLP_emotions_model = embedding_base_MLP.fit(embeddings_train, embedding_emotions_train)\n",
    "with open('embedding_base_MLP_emotions_model.pkl', 'wb') as file:\n",
    "    pickle.dump(embedding_base_MLP_emotions_model, file)\n",
    "\n",
    "embedding_base_MLP_sentiments_model = embedding_base_MLP.fit(embeddings_train, embedding_sentiments_train)\n",
    "with open('embedding_base_MLP_sentiments_model.pkl', 'wb') as file:\n",
    "    pickle.dump(embedding_base_MLP_sentiments_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('embedding_base_MLP_emotions_model.pkl', 'rb') as file:\n",
    "    embedding_base_MLP_emotions_model = pickle.load(file)\n",
    "    embedding_base_MLP_emotions_pred = embedding_base_MLP_emotions_model.predict(embeddings_test)\n",
    "\n",
    "    # 3.6 Classification Performance\n",
    "    f = open('embedding_base_MLP_emotions_performance.txt', 'w')\n",
    "    f.write('Base MLP Performance for emotions\\n')\n",
    "    f.write('---------------------------------\\n')\n",
    "    f.write('Hyper-parameters: ')\n",
    "    f.write(str(embedding_base_MLP_emotions_model.get_params()))\n",
    "    f.write('\\n\\nConfusion matrix:\\n')\n",
    "    f.write(str(confusion_matrix(embedding_emotions_test, embedding_base_MLP_emotions_pred)))\n",
    "    f.write('\\n\\nClassification report:\\n')\n",
    "    f.write(str(classification_report(embedding_emotions_test, embedding_base_MLP_emotions_pred)))\n",
    "    f.close()\n",
    "\n",
    "with open('embedding_base_MLP_sentiments_model.pkl', 'rb') as file:\n",
    "    embedding_base_MLP_sentiments_model = pickle.load(file)\n",
    "    embedding_base_MLP_sentiments_pred = embedding_base_MLP_sentiments_model.predict(embeddings_test)\n",
    "\n",
    "    # 3.6 Classification Performance\n",
    "    f = open('embedding_base_MLP_sentiments_performance.txt', 'w')\n",
    "    f.write('Base MLP Performance for sentiments\\n')\n",
    "    f.write('---------------------------------\\n')\n",
    "    f.write('Hyper-parameters: ')\n",
    "    f.write(str(embedding_base_MLP_sentiments_model.get_params()))\n",
    "    f.write('\\n\\nConfusion matrix:\\n')\n",
    "    f.write(str(confusion_matrix(embedding_sentiments_test, embedding_base_MLP_sentiments_pred)))\n",
    "    f.write('\\n\\nClassification report:\\n')\n",
    "    f.write(str(classification_report(embedding_sentiments_test, embedding_base_MLP_sentiments_pred)))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 - Top MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_top_MLP_hyper_params = {\n",
    "    'activation': ['logistic', 'tanh', 'relu', 'identity'],\n",
    "    'hidden_layer_sizes': [(30, 50), (10, 10, 10)],\n",
    "    'solver': ['adam', 'sgd']\n",
    "}\n",
    "\n",
    "embedding_top_MLP = MLPClassifier(max_iter=1)\n",
    "embedding_top_MLP_grid_search = GridSearchCV(estimator=top_MLP, param_grid=embedding_top_MLP_hyper_params)\n",
    "\n",
    "embedding_top_MLP_emotions_model = embedding_top_MLP_grid_search.fit(embeddings_train, embedding_emotions_train)\n",
    "with open('embedding_top_MLP_emotions_model.pkl', 'wb') as file:\n",
    "    pickle.dump(embedding_top_MLP_emotions_model, file)\n",
    "\n",
    "embedding_top_MLP_sentiments_model = embedding_top_MLP_grid_search.fit(embeddings_train, embedding_sentiments_train)\n",
    "with open('embedding_top_MLP_sentiments_model.pkl', 'wb') as file:\n",
    "    pickle.dump(embedding_top_MLP_sentiments_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('embedding_top_MLP_emotions_model.pkl', 'rb') as file:\n",
    "    embedding_top_MLP_emotions_model = pickle.load(file)\n",
    "    embedding_top_MLP_emotions_pred = embedding_top_MLP_emotions_model.predict(embeddings_test)\n",
    "\n",
    "    # 3.6 Classification Performance\n",
    "    f = open('embedding_top_MLP_emotions_performance.txt', 'w')\n",
    "    f.write('Base MLP Performance for emotions\\n')\n",
    "    f.write('---------------------------------\\n')\n",
    "    f.write('Hyper-parameters: ')\n",
    "    f.write(str(embedding_top_MLP_emotions_model.get_params()))\n",
    "    f.write('\\n\\nBest parameters: ')\n",
    "    f.write(str(embedding_top_MLP_emotions_model.best_params_))\n",
    "    f.write('\\n\\nConfusion matrix:\\n')\n",
    "    f.write(str(confusion_matrix(embedding_emotions_test, embedding_top_MLP_emotions_pred)))\n",
    "    f.write('\\n\\nClassification report:\\n')\n",
    "    f.write(str(classification_report(embedding_emotions_test, embedding_top_MLP_emotions_pred)))\n",
    "    f.close()\n",
    "\n",
    "with open('embedding_top_MLP_sentiments_model.pkl', 'rb') as file:\n",
    "    embedding_top_MLP_sentiments_model = pickle.load(file)\n",
    "    embedding_top_MLP_sentiments_pred = embedding_top_MLP_sentiments_model.predict(embeddings_test)\n",
    "\n",
    "    # 3.6 Classification Performance\n",
    "    f = open('embedding_top_MLP_sentiments_performance.txt', 'w')\n",
    "    f.write('Base MLP Performance for sentiments\\n')\n",
    "    f.write('---------------------------------\\n')\n",
    "    f.write('Hyper-parameters: ')\n",
    "    f.write(str(embedding_top_MLP_sentiments_model.get_params()))\n",
    "    f.write('\\n\\nBest parameters: ')\n",
    "    f.write(str(embedding_top_MLP_sentiments_model.best_params_))\n",
    "    f.write('\\n\\nConfusion matrix:\\n')\n",
    "    f.write(str(confusion_matrix(embedding_sentiments_test, embedding_top_MLP_sentiments_pred)))\n",
    "    f.write('\\n\\nClassification report:\\n')\n",
    "    f.write(str(classification_report(embedding_sentiments_test, embedding_top_MLP_sentiments_pred)))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 - Classification Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See output above for 3.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3.8 - Exploring other pretrained embedding models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8.1 - Loading embedding models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki = api.load(\"fasttext-wiki-news-subwords-300\")\n",
    "ruscorpora = api.load(\"word2vec-ruscorpora-300\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8.2 - Post embeddings using models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_embeddings = []\n",
    "\n",
    "for post in posts:\n",
    "    post_tokens = word_tokenize(post)\n",
    "    word_embeddings = []\n",
    "\n",
    "    for token in post_tokens:\n",
    "        try:\n",
    "            word_embedding = wiki[token]\n",
    "            word_embeddings.append(word_embedding)\n",
    "        except KeyError: # If token is not present in Word2Vec model\n",
    "            continue\n",
    "\n",
    "    wiki_embedding = np.nanmean(word_embeddings)\n",
    "    wiki_embeddings.append(wiki_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "ruscorpora_embeddings = []\n",
    "\n",
    "for post in posts:\n",
    "    post_tokens = word_tokenize(post)\n",
    "    word_embeddings = []\n",
    "\n",
    "    for token in post_tokens:\n",
    "        try:\n",
    "            word_embedding = ruscorpora[token]\n",
    "            print(ruscorpora[token])\n",
    "        except KeyError: # If token is not present in Word2Vec model\n",
    "            continue\n",
    "\n",
    "    ruscorpora_embedding = np.nanmean(word_embeddings)\n",
    "    if not math.isnan(ruscorpora_embedding): ruscorpora_embeddings.append(ruscorpora_embedding)\n",
    "    else: ruscorpora_embeddings.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8.3 - Train-Test split of model embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_embeddings = np.array(wiki_embeddings).reshape(-1, 1)\n",
    "\n",
    "wikis_train, wikis_test, wiki_emotions_train, wiki_emotions_test = train_test_split(wiki_embeddings, y_emotions, test_size=0.2, random_state=0)\n",
    "wikis_train, wikis_test, wiki_sentiments_train, wiki_sentiments_test = train_test_split(wiki_embeddings, y_sentiments, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruscorpora_embeddings = np.array(ruscorpora_embeddings).reshape(-1, 1)\n",
    "\n",
    "rucorporas_train, ruscorporas_test, ruscorpora_emotions_train, ruscorpora_emotions_test = train_test_split(ruscorpora_embeddings, y_emotions, test_size=0.2, random_state=0)\n",
    "ruscorporas_train, ruscorporas_test, ruscorpora_sentiments_train, ruscorpora_sentiments_test = train_test_split(ruscorpora_embeddings, y_sentiments, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8.4 - Top MLP Training using models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_top_MLP_hyper_params = {\n",
    "    'activation': ['logistic', 'tanh', 'relu', 'identity'],\n",
    "    'hidden_layer_sizes': [(30, 50), (10, 10, 10)],\n",
    "    'solver': ['adam', 'sgd']\n",
    "}\n",
    "\n",
    "wiki_top_MLP = MLPClassifier(max_iter=1)\n",
    "wiki_top_MLP_grid_search = GridSearchCV(estimator=wiki_top_MLP, param_grid=wiki_top_MLP_hyper_params)\n",
    "\n",
    "wiki_top_MLP_emotions_model = wiki_top_MLP_grid_search.fit(wikis_train, wiki_emotions_train)\n",
    "with open('wiki_top_MLP_emotions_model.pkl', 'wb') as file:\n",
    "    pickle.dump(wiki_top_MLP_emotions_model, file)\n",
    "\n",
    "wiki_top_MLP_sentiments_model = wiki_top_MLP_grid_search.fit(wikis_train, wiki_sentiments_train)\n",
    "with open('wiki_top_MLP_sentiments_model.pkl', 'wb') as file:\n",
    "    pickle.dump(wiki_top_MLP_sentiments_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruscorpora_top_MLP_hyper_params = {\n",
    "    'activation': ['logistic', 'tanh', 'relu', 'identity'],\n",
    "    'hidden_layer_sizes': [(30, 50), (10, 10, 10)],\n",
    "    'solver': ['adam', 'sgd']\n",
    "}\n",
    "\n",
    "ruscorpora_top_MLP = MLPClassifier(max_iter=1)\n",
    "ruscorpora_top_MLP_grid_search = GridSearchCV(estimator=ruscorpora_top_MLP, param_grid=ruscorpora_top_MLP_hyper_params)\n",
    "\n",
    "ruscorpora_top_MLP_emotions_model = ruscorpora_top_MLP_grid_search.fit(ruscorporas_train, ruscorpora_emotions_train)\n",
    "with open('ruscorpora_top_MLP_emotions_model.pkl', 'wb') as file:\n",
    "    pickle.dump(ruscorpora_top_MLP_emotions_model, file)\n",
    "\n",
    "ruscorpora_top_MLP_sentiments_model = ruscorpora_top_MLP_grid_search.fit(ruscorporas_train, ruscorpora_sentiments_train)\n",
    "with open('ruscorpora_top_MLP_sentiments_model.pkl', 'wb') as file:\n",
    "    pickle.dump(ruscorpora_top_MLP_sentiments_model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8.5 - MLP Performance of MLP using pretrained embedding models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('wiki_top_MLP_emotions_model.pkl', 'rb') as file:\n",
    "    wiki_top_MLP_emotions_model = pickle.load(file)\n",
    "    wiki_top_MLP_emotions_pred = wiki_top_MLP_emotions_model.predict(wikis_test)\n",
    "\n",
    "    # 3.8 Classification Performance\n",
    "    f = open('wiki_top_MLP_emotions_performance.txt', 'w')\n",
    "    f.write('Base MLP Performance for emotions\\n')\n",
    "    f.write('---------------------------------\\n')\n",
    "    f.write('Hyper-parameters: ')\n",
    "    f.write(str(wiki_top_MLP_emotions_model.get_params()))\n",
    "    f.write('\\n\\nBest parameters: ')\n",
    "    f.write(str(wiki_top_MLP_emotions_model.best_params_))\n",
    "    f.write('\\n\\nConfusion matrix:\\n')\n",
    "    f.write(str(confusion_matrix(wiki_emotions_test, wiki_top_MLP_emotions_pred)))\n",
    "    f.write('\\n\\nClassification report:\\n')\n",
    "    f.write(str(classification_report(wiki_emotions_test, wiki_top_MLP_emotions_pred)))\n",
    "    f.close()\n",
    "\n",
    "with open('wiki_top_MLP_sentiments_model.pkl', 'rb') as file:\n",
    "    wiki_top_MLP_sentiments_model = pickle.load(file)\n",
    "    wiki_top_MLP_sentiments_pred = wiki_top_MLP_sentiments_model.predict(wikis_test)\n",
    "\n",
    "    # 3.8 Classification Performance\n",
    "    f = open('wiki_top_MLP_sentiments_performance.txt', 'w')\n",
    "    f.write('Base MLP Performance for sentiments\\n')\n",
    "    f.write('---------------------------------\\n')\n",
    "    f.write('Hyper-parameters: ')\n",
    "    f.write(str(wiki_top_MLP_sentiments_model.get_params()))\n",
    "    f.write('\\n\\nBest parameters: ')\n",
    "    f.write(str(wiki_top_MLP_sentiments_model.best_params_))\n",
    "    f.write('\\n\\nConfusion matrix:\\n')\n",
    "    f.write(str(confusion_matrix(wiki_sentiments_test, wiki_top_MLP_sentiments_pred)))\n",
    "    f.write('\\n\\nClassification report:\\n')\n",
    "    f.write(str(classification_report(wiki_sentiments_test, wiki_top_MLP_sentiments_pred)))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ruscorpora_top_MLP_emotions_model.pkl', 'rb') as file:\n",
    "    ruscorpora_top_MLP_emotions_model = pickle.load(file)\n",
    "    ruscorpora_top_MLP_emotions_pred = ruscorpora_top_MLP_emotions_model.predict(ruscorporas_test)\n",
    "\n",
    "    # 3.8 Classification Performance\n",
    "    f = open('ruscorpora_top_MLP_emotions_performance.txt', 'w')\n",
    "    f.write('Base MLP Performance for emotions\\n')\n",
    "    f.write('---------------------------------\\n')\n",
    "    f.write('Hyper-parameters: ')\n",
    "    f.write(str(ruscorpora_top_MLP_emotions_model.get_params()))\n",
    "    f.write('\\n\\nBest parameters: ')\n",
    "    f.write(str(ruscorpora_top_MLP_emotions_model.best_params_))\n",
    "    f.write('\\n\\nConfusion matrix:\\n')\n",
    "    f.write(str(confusion_matrix(ruscorpora_emotions_test, ruscorpora_top_MLP_emotions_pred)))\n",
    "    f.write('\\n\\nClassification report:\\n')\n",
    "    f.write(str(classification_report(ruscorpora_emotions_test, ruscorpora_top_MLP_emotions_pred)))\n",
    "    f.close()\n",
    "\n",
    "with open('ruscorpora_top_MLP_sentiments_model.pkl', 'rb') as file:\n",
    "    ruscorpora_top_MLP_sentiments_model = pickle.load(file)\n",
    "    ruscorpora_top_MLP_sentiments_pred = ruscorpora_top_MLP_sentiments_model.predict(ruscorporas_test)\n",
    "\n",
    "    # 3.8 Classification Performance\n",
    "    f = open('ruscorpora_top_MLP_sentiments_performance.txt', 'w')\n",
    "    f.write('Base MLP Performance for sentiments\\n')\n",
    "    f.write('---------------------------------\\n')\n",
    "    f.write('Hyper-parameters: ')\n",
    "    f.write(str(ruscorpora_top_MLP_sentiments_model.get_params()))\n",
    "    f.write('\\n\\nBest parameters: ')\n",
    "    f.write(str(ruscorpora_top_MLP_sentiments_model.best_params_))\n",
    "    f.write('\\n\\nConfusion matrix:\\n')\n",
    "    f.write(str(confusion_matrix(ruscorpora_sentiments_test, ruscorpora_top_MLP_sentiments_pred)))\n",
    "    f.write('\\n\\nClassification report:\\n')\n",
    "    f.write(str(classification_report(ruscorpora_sentiments_test, ruscorpora_top_MLP_sentiments_pred)))\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
