Base MLP Performance for emotions
---------------------------------
Hyper-parameters: {'cv': None, 'error_score': nan, 'estimator__alpha': 1.0, 'estimator__class_prior': [0.021, 0.014, 0.329, 0.021, 0.064, 0.043, 0.021, 0.057, 0.043, 0.021, 0.079, 0.014, 0.007, 0.029, 0.029, 0.057, 0.014, 0.029, 0.021, 0.036, 0.021, 0.007, 0.007], 'estimator__fit_prior': True, 'estimator': MultinomialNB(class_prior=[0.021, 0.014, 0.329, 0.021, 0.064, 0.043, 0.021,
                           0.057, 0.043, 0.021, 0.079, 0.014, 0.007, 0.029,
                           0.029, 0.057, 0.014, 0.029, 0.021, 0.036, 0.021,
                           0.007, 0.007]), 'n_jobs': None, 'param_grid': {'alpha': [1e-10, 0.5, 1.5, 3.0]}, 'pre_dispatch': '2*n_jobs', 'refit': True, 'return_train_score': False, 'scoring': None, 'verbose': 0}

Best parameters: {'alpha': 1e-10}

Confusion matrix:
[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0 10  1  0  0  1  0  1  1  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  1  0  0  0  0  0  0  0  0  1  0  0  0  1  1  0  0]
 [ 0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0]]

Classification report:
              precision    recall  f1-score   support

           1       0.00      0.00      0.00         0
           2       0.67      0.71      0.69        14
           3       0.00      0.00      0.00         0
           4       0.00      0.00      0.00         2
           6       0.00      0.00      0.00         1
           7       0.00      0.00      0.00         0
           8       0.00      0.00      0.00         1
           9       0.00      0.00      0.00         0
          10       0.00      0.00      0.00         4
          13       0.00      0.00      0.00         1
          15       0.00      0.00      0.00         0
          16       0.00      0.00      0.00         1
          17       0.00      0.00      0.00         1
          18       0.00      0.00      0.00         1
          19       0.00      0.00      0.00         0
          20       0.00      0.00      0.00         0
          21       0.00      0.00      0.00         1
          24       0.00      0.00      0.00         1

    accuracy                           0.36        28
   macro avg       0.04      0.04      0.04        28
weighted avg       0.33      0.36      0.34        28
